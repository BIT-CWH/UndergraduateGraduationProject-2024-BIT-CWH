# L4 microkernels: The lessons from 20 years of research and deployment
# 摘要
本文研究了从原始L4到最新一代L4内核的设计和实现的演变，总结了这20年中关于微内核设计和实现的经验教训。本文特别关注seL4，它把L4模型推得最远，并且是第一个对其实现进行完整形式验证以及对最坏情况执行时间进行合理分析的操作系统内核。尽管微内核在发展中发生了很大变化，但最小性、通用性和IPC性能仍然是设计和实现的主要驱动力。   
# 介绍
20 年前，Liedtke [1993a] 用他的 L4 内核证明了微内核 IPC 可以很快，比当代微内核快 10-20 倍。  
微内核最小化了内核提供的功能：内核提供了一组通用机制，而用户模式服务器则实现了实际的操作系统（OS）服务[Brinch Hansen 1970;Levin 等人，1975 年]。应用程序代码通过进程间通信 （IPC） 机制（通常是消息传递）与服务器通信来获取系统服务。因此，IPC 处于任何服务调用的关键路径上，低 IPC 成本至关重要。  
到 1990 年代初，IPC 性能已成为微内核的致命弱点：单向消息的成本过高，约为 100 μs，导致了将核心服务移回内核的趋势 [Condict et al. 1994]。也有人认为，高IPC成本是基于微内核的系统结构的固有的结果[Chen和Bershad 1993]。  
在这种情况下，Liedtke所展示的IPC成本的量级改进是相当显着的。随后，他讨论了L4的理念和机制 [Liedtke 1995， 1996]，在L4上演示了半虚拟化的 Linux，开销只有百分之几 [Hartig et al. ̈ 1997]，在数十亿个移动设备和安全关键系统中部署 L4 内核;最后，L4 对其他研究系统也有很强的影响。  
本文中研究了自 1990 年代中期以来 L4 的发展。具体来说，研究了现代L4内核的运作机制与 Liedtke 的原始设计和实现规则有何关系，以及他的哪些微内核“基本要素”通过了时间的考验。本文还研究了过去的经验教训如何影响最新一代 L4 微内核的设计，例如 seL4 [Klein et al. 2009]，并指出了其他当前 L4 版本在哪些方面做出了不同的设计决策。

# 背景
Background部分介绍了L4家族群  
# 微内核设计
## IPC
### 同步IPC 
最初的 L4 支持同步（交会式）IPC 作为唯一的通信、同步和信号机制。同步 IPC 避免了内核中的缓冲以及与之相关的管理和复制成本。在其最简单的版本（在寄存器中传递的短消息）中，它只不过是一个上下文开关，使消息寄存器保持不变。  
这种模型的显着缺点：它强制在本来简单的系统进行多线程设计，导致同步具有复杂性。例如，系统缺乏类似于UNIX select（）的功能，需要每个中断源使用单独的线程，而单线程服务器又无法同时等待客户端请求和中断。  
此外，同步消息传递显然是跨处理器内核同步活动的错误方式。在单个处理器上，线程之间的通信最终需要进行上下文切换，将其与通信相结合可以最大程度地减少开销。因此，经典的 L4 IPC 模型是绕过调度程序的用户控制的上下文切换模型。  
L4-embedded中通过添加Notification（一种简单的、非阻塞的信令机制）解决了这个问题。后来，seL4的Notification objetc改进了这个模型：Notification包含一组标志，即Notification word。对Notification object的信号操作在不阻塞的情况下设置标志的子集。可以通过轮询或等待（阻塞）信号来检查Notification word。Notification不是异步IPC，而是同步与通信的解耦，对于有效利用硬件的并发性至关重要。  
总之，与大多数其他L4内核一样，seL4 保留了同步IPC的模型，但通过类似信号量的Notification对其进行了增强。OKL4 已经完全放弃了同步 IPC，取而代之的是虚拟 IRQ（类似于通知）。NOVA通过计数信号量增强了同步IPC [Steinberg和Kauer 2010]，而Fiasco.OC也通过虚拟IRQ增强了同步IPC。
### IPC消息结构
#### 短消息
原始的消息传递采用消息寄存器：内核始终从发送方的上下文启动 IPC，并在不更改消息寄存器的情况下切换到接收方的上下文。缺点是依赖于体系结构且（尤其是在 x86 上）支持消息的大小较小，且随着ABI的参数更改而变动。  
Pistachio引入了虚拟消息寄存器的概念：将其中一些虚拟寄存器映射到物理寄存器，其余的则包含每个线程地址空间的固定部分中。储存在固定部分的方式可确保访问按照类似访问寄存器的方式进行，不会出现页面错误。seL4 和 Fiasco.OC 继续使用这种方法。此模型优势在于，虚拟消息寄存器大大提高了跨架构的可移植性。此外，它们还减少了中等大小的邮件超过物理寄存器数量的性能损失。但随着时间的流逝，通过寄存器的消息传输优势不再，因为上下文切换的成本主导了 IPC 性能。 
#### 长消息 
在原始 L4 中，“长”消息可以在单个 IPC 调用中指定多个缓冲区，以摊销硬件和上下文切换成本。长消息可以通过单个副本传递：在发送方的上下文中发起，内核在接收方的地址空间中设置一个临时映射窗口，覆盖为消息，并直接复制到接收方。  
这可能导致在源地址空间或目标地址空间中的复制期间触发页面错误，这需要内核处理嵌套异常。此外，处理此类异常需要调用用户级页面错误处理程序。必须在内核仍在处理 IPC 系统调用时调用处理程序，但调用必须假装错误发生在正常的用户模式执行期间。返回时，必须重新建立原始系统调用上下文。结果是内核的复杂性大大增加，许多棘手的极端情况可能会在实现中出现错误
虽然长消息IPC提供了在低开销的情况下无法实现的功能，但在实践中很少使用：批量数据传输首选共享缓冲区，而虚拟寄存器的引入也增加了支持的小型消息的大小。  
对于 seL4 来说，有更充分的理由不支持长消息：形式化验证方法明确避免了内核中的任何并发性[Klein et al. 2009]，而嵌套异常引入了一定程度的并发性。嵌套异常难以进行形式化验证，虽然可以通过额外检查来避免上述页面错误，从而避免嵌套异常，但是十分复杂，且且降低内核性能。
### IPC目的地
原始L4将线程作为IPC操作的目标。其动机是避免与间接水平相关的缓存和TLB污染。该模型要求线程ID是唯一标识符。但该模型有一个缺点，即信息隐藏性差。多线程服务器必须向客户端公开其内部结构，以分散客户端负载，或者使用网关线程，这可能会成为瓶颈，并会带来额外的通信和同步开销。  
受EROS[Shapiro et al. 1999]的影响，seL4和Fiasco.OC [Lackorzynski 和 Warg 2009]）采用IPC端点作为IPC目的地。seL4端点本质上是端口：待处理发送方或接收方队列现在是一个单独的内核对象，而不是接收方线程控制块TCB的一部分。与 Mach 端口 [Accetta et al. 1986] 不同，IPC端点不提供任何缓冲。  
为了帮助服务器识别客户端，而不需要每个客户端的端点，seL4提供了徽章功能。具有不同徽章但派生自同一原始功能的功能指向相同的端点对象，但在调用时将徽章作为发送方的标识传递给接收方。
### IPC超时
阻塞IPC机制为拒绝服务（DOS）攻击创造了机会。为了防止此类攻击，原始L4中的IPC操作设置了超时。超时值以浮点格式编码，支持从一毫秒到周的零值、无穷大和有限值。它们增加了管理唤醒列表的复杂性。然而，设置超时作为DOS防御措施几乎没有用处。在系统中，没有理论甚至没有好的启发式方法来选择超时值；在实践中，只使用了值零和无穷大：客户端以无限超时发送和接收，而服务器以无限超时等待请求。  
在放弃了长IPC之后，在L4-embedded中用一个支持轮询（零超时）或阻塞（无限超时）选择的标志替换了超时。只需要两个标志，一个用于发送，一个用于接收阶段。sel4也采用此模型。而完全异步模型（例如 OKL4 的模型）与超时不兼容，并且没有需要超时的 DOS 问题。  
此外，超时也可用于通过等待来自不存在线程的消息来定时睡眠。  
### 通信控制
在最初的L4中，内核将发送方的ID传递给接收方。这允许服务器通过忽略不需要的消息来实现一种自由访问控制形式。但是服务器可能会受到恶意客户端的消息轰炸，接收并检查此类消息有一定时间开销。因此，此类消息可能构成 DOS 攻击，只有通过内核支持才能避免，内核支持首先可以防止发送不需要的消息 [Liedtke et al. 1997b]。强制性访问控制策略还需要一种用于调解和授权通信的机制。  
最初的L4通过一种称为部落和酋长的机制提供了这一点：进程按照“部落”的等级制度进行组织，每个部落都有一个指定的“酋长”。在部落内部，所有消息都是自由传输的，内核保证了消息的完整性。但是，跨越部落边界的信息，无论是传出还是传入，都会被重定向到部落的酋长。该机制还支持对不受信任的子系统进行限制 [Lipner 1975]。  
Liedtke [1995]认为，部落和酋长模型在每个IPC操作中只增加了两个周期，因为部落ID被编码在线程ID中以便快速比较。但是，低开销仅适用于可以直接通信的情况。一旦邮件被重定向，每个这样的重定向都会将两条邮件添加到（逻辑上）单个往返 IPC，这是一个巨大的开销。此外，严格的线程层次结构在实践中是笨拙的。对于强制访问控制，该模型很快恶化为每个进程为一个酋长。由于这些缺点，许多L4内核实现没有实现部落和酋长，或者在构建时禁用了该功能，但这意味着无法控制 IPC。该问题最终通过在Endpoint上灵活地以Capability为中介的访问控制得到解决。  
## 用户级设备驱动
最小性原则的一个最重要的结果，并且也许是 L4（或者更确切地说，它的前身 L3 [Liedtke et al. 1991]）最具争议的功能，是使所有设备驱动程序都成为用户级进程。作为驱动程序，进入内核将消除任何保证，并且目前在现实世界的系统中验证大量驱动程序代码是遥不可及的。  
但少数驱动程序最好仍保留在内核中。在现代 L4 内核中，这通常指一个计时器驱动程序（用于在用户时间片结束时抢占用户进程）以及中断控制器的驱动程序（将中断安全地分发到用户级进程）。  
用户级驱动程序模型与模块中断紧密耦合为 IPC 消息，内核将这些消息发送到驱动程序。多年来，模型的细节（来自虚拟线程的 IPC 与上调）以及关联和确认协议发生了变化（一次又一次地更改），但一般方法仍然适用。  
最显著的变化是从IPC转向Notification作为中断传递的机制。这里的主要驱动因素是实现简化，因为消息传递需要模拟虚拟内核线程作为中断 IPC 的来源，而发送信号的Notification与硬件的功能自然匹配。  
用户级驱动程序受益于虚拟化驱动的硬件改进。I/O 内存管理单元 （IOMMU） 已为驱动程序启用安全直通设备访问。用户级驱动程序也受益于硬件开发，这些硬件开发减少了中断开销，特别是现代网络接口上的中断合并支持。  
当然，用户级驱动程序现在已经成为主流， Linux、Windows 和 MacOS 上都支持这种方式（尽管不被鼓励）。这些系统的开销通常高于IPC高度优化的 L4。但我们在过去就已经证明，即使在 Linux 上也可以实现低开销，至少在上下文切换友好的硬件上是这样 [Leslie et al. 2005a]。
## 资源管理
最初的 L4 的资源管理，就像它的通信控制方法一样，很大程度上是基于进程层次结构的。这适用于管理进程和虚拟内存。层次结构是管理和恢复资源的有效方法，它提供了约束子系统的模型：系统机制将子级的权限限制为其父级的子集。代价是管理较为死板。此外，层次结构是一种策略形式，因此与微内核的原则（策略与机制分离，内核提供机制）不匹配。  
Capabilities可以提供一种摆脱层次结构限制的方法，这是所有现代 L4 内核采用基于Capabilities的访问控制的几个原因之一。在这里，我们研究了原始 L4 模型中出现的最重要的资源管理问题，以及我们现在如何处理这些问题。
### 进程层次结构
L4 没有最高级（first-class）进程概念，它采用一个更高级别的抽象，由一个地址空间（由页表表示）和许多关联的线程组成。这些会消耗内核资源，并且未经检查地分配 TCB 和页表很容易导致拒绝服务。最初的 L4 通过进程层次结构来处理这个问题：“Task IDs”本质上是地址空间上的Capabilities，允许创建和删除。  
这些ID数量有限，由内核分发且先到先得。它们可以被委派，但只能在层次结构中向上或向下委派。它们还与用于 IPC 控制的线程层次结构密切相关。在典型的设置中，初始用户进程（initial user process）将在创建任何其他进程之前获取所有Task ID。  
也许不足为奇的是，这种强加特定政策的模式被证明是僵化和具有限制性的，它最终被成熟的Capability机制所取代。
### 递归页面映射
原始 L4 将物理内存帧的权限与现有页面映射绑定在一起。如果在其地址空间中具有对一个页面的有效的映射，则进程有权将该页面映射到另一个地址空间。进程可以授权别的进程其中一个它持有的页面（而非映射），该页面及其任何权限将从授予者那里删除。映射（而非授权）可以通过取消映射操作撤销。进程的地址空间创建时为空，并使用映射基元进行填充。  
递归映射模型基于在原始地址空间 σ0 中，该地址空间接收内核启动后剩余的所有空闲帧的恒等映射。σ0 是在启动时创建的，所属于所有进程的页面错误处理程序。它将它的页面映射到第一个请求该页面的进程，该进程通过地址空间中的缺页错误来请求。  
请注意，虽然 L4 内存模型创建了源自每个页帧的映射层次结构，但它不会强制使用地址空间的分层视图：映射是通过 IPC 建立的，类似于通过 IPC 消息传输capability。一个进程可以将它的页面映射到它被允许向其发送IPC的任何其他进程，前提是接收方同意接收映射。与 Mach 相比，L4 没有内存对象语义，只有低级地址空间管理机制，这些机制更接近 Mach 的内核内 pmap 接口，而不是其用户可见的内存对象抽象 [Rashid et al. 1988]。内存对象、写入时复制和影子链都是用户级创建的抽象或实现方法。   
递归映射模型在概念上简单而优雅，Liedtke 显然对此感到自豪：它在许多文章中都占有重要地位，包括第一篇文章 [Liedtke 1993a]，以及他的所有演讲。然而，经验表明，这个模型存在着明显的缺点。  
为了支持以页面为粒度的吊销，递归地址空间模型需要以映射数据库的形式进行大量簿记。此外，L4 内存模型的通用性允许两个恶意串通好的进程通过递归地将同一帧映射到彼此地址空间中的不同页面来迫使内核消耗大量内存，这是一种潜在的 DOS 攻击，尤其是在 64 位硬件上，这只能通过控制 IPC 来防止（通过可怕的氏族酋长， 参见第 3.2.5 节）。  
L4-embedded 删除了递归映射模型，因为在实际使用中，即使没有恶意进程，映射数据库也会消耗 25% 到 50% 的内核内存。我们用一个更能反应硬件的模型取代了它，其中映射总是源于一系列物理内存帧范围。  
这种方法的代价是丢失对内存的细粒度委派和撤销（而不是通过对页表进行暴力扫描）。因此作者认为它只能暂时止痛。OKL4 在一定程度上扩展了这个最小模型，但没有实现原始模型的通用性和细粒度控制。  
当然，在基于Capability的系统中，使用标准获取-授予模型的变体[Lipton和Snyder 1977]，可以很容易地实现映射控制。这就是 seL4 提供的：映射权是通过指向物理页帧的capability传达的，而不是通过访问由该物理页帧支持的虚拟页面来传达的，因此 seL4 的模型不是递归的。即使具有页帧capability，映射也会受到用于记录映射的显式内核内存模型的严格限制，如第 3.4.3 节所述。  
Xen 提供了一个有趣的比较点 [Fraser et al. 2004]。授权表允许创建（基于拥有有效映射）的帧capability，该capability可以传递到另一个域以建立共享映射。最近的一项提案扩展了授权表，以允许撤销页帧 [Ram 等人，2010 年]。内存映射原语的语义与 seL4 的语义大致相似，但缺少页面错误的传播。在 Xen 的案例中，支持细粒度委派和吊销的开销仅在共享实例中存在。  
NOVA 和 Fiasco.OC 都保留了递归地址空间模型，其映射权限由拥有有效映射来确定。因此无法限制映射，从而无法限制簿记分配的问题由 Fiasco.OC 中的每个任务拥有内核内存池解决。  
现有的细粒度委派和吊销的 L4 地址空间模型代表了机制的通用性和最小性与可能更节省空间的域特定方法之间的不同权衡。  
总之，一些 L4 内核保留了递归地址空间构造的模型，而 seL4 和 OKL4 则从页帧发起映射。只有 seL4 提供页面访问的细粒度委派。
### 内核内存
虽然Capabilities为委派提供了一个简洁而优雅的模型，但它们本身并不能解决资源管理问题。具有映射权限的恶意线程仍然可以使用它来创建大量映射，迫使内核消耗大量内存来存储元数据来对系统进行潜在的DOS攻击。  
传统 L4 内核有一个固定大小的堆，内核从中为其数据结构分配内存。最初的 L4 有一个称为 σ1 的内核寻呼机，内核可以通过它从用户空间请求额外的内存。这并不能解决恶意（或有缺陷）的用户代码不合理的内存消耗的问题，且只会转移问题。因此，大多数 L4 内核不支持 σ1。  
大多数其他操作系统都存在的基本问题是共享内核堆对用户进程的隔离存在不足。因此，一个完美的方法必须能够提供完全隔离。根本问题是，即使在权限由capabilities表示的系统中，如果Capability机制之外存在资源（如内核内存），也无法推断系统的安全状态。  
将内存作为用户级内容缓存进行管理的内核们只能部分解决此问题。虽然基于缓存的方法消除了基于耗尽内存的 DOS 攻击的机会，但它们无法实现内核内存的严格隔离。严格隔离是功能隔离或实时系统的先决条件，并且可能会引入侧信道。  
Liedtke et al. [1997b] 研究了这个问题，并提出了一个进程一个内核堆的方案以及一种在内核内存耗尽时向内核捐赠额外内存的机制。NOVA、Fiasco 和 OKL4 都采用了这种方法的变体。一个进程的一个内核堆的方案通过消除对分配的控制来简化用户级别，代价是放弃了在不破坏进程的情况下撤销分配的能力，以及直接推断已分配内存的能力，而不仅仅是限制它。社区仍在探索在这方面的权衡。  
seL4 采取了截然不同的方法：它用于管理内核内存的模型是 seL4 对操作系统设计的主要贡献。出于对资源使用和隔离进行推断的愿望，除了内核用于启动所使用的大小固定的内存，包括其严格绑定的堆栈，作者将所有内核内存都置于capabilities传递的权限之下。具体来说，seL4 完全删除了内核堆，并为用户空间提供了一种在内核分配数据结构时识别被授权的内核内存的机制。这个方案的副产物是减少了内核的大小和复杂性，这对于验证而言是一个主要好处。  
问题的关键是使所有内核对象显式化，并受基于capabilities的访问控制。这种方法的灵感来自基于硬件的capability系统，尤其是 CAP [Needham and Walker 1977]，其中被硬件翻译的capabilities直接指向内存。HiStar [Zeldovich et al. 2011] 也使所有内核对象显式化，但它采用缓存方法来进行内存管理。  
当然，用户可见的内核对象并不意味着对内核对象有权限的进程可以直接读取或写入它。对应Capability提供调用特定对象的部分方法的权限，其中包括销毁对象（对象一旦创建，大小永远不会改变）。至关重要的是，内核对象类型包括未使用的内存，在 seL4 中称为 Untyped，可用于创建其他对象。  
具体来说，在 Untyped 上唯一可能的操作是将其部分retype为某个对象类型。新对象与原始 Untyped 的关系记录在Capability派生树中，该树还记录其他类型的capability派生，例如仅具有低级权限的capability副本。一旦某些 Untyped 被retype，对原始 Untyped 的（对应部分）的唯一可能的操作是撤消派生对象（见下文）。
Retype是在 seL4 中创建对象的唯一方法。因此，通过限制对 Untyped 内存的访问，系统可以控制资源分配。Retype方法还可以生成较小的 Untyped 对象，然后这些对象后续可以被单独管理，这是委派资源管理的关键。从 Untyped 派生还确保了内核的完整性，即没有两个typed对象是空间上重叠的。  
表 III 给出了完整的 seL4 对象类型集及其在 32 位 ARM 处理器中的使用，在 x86 结构中也非常相似。用户空间只能直接访问（加载/存储/获取）与Frame关联的内存。而通过将Frame Capability插入Page Table，Frame 被映射到其地址空间。
对象|描述
-|-
TCB|进程控制块
Cnode|Capability存储
Endpoint|用于IPC的类似于端口的会合对象
Notification|用于代表二进制信号的标志的集合
Page Directory|ARM虚拟内存的Top-level页表
Page Table|ARM虚拟内存的Leaf页表
Frame|大小为4KB、64KB、1MB或16MB的，可以被页表用于映射形成虚拟内存的对象
Untyped Memory|大小为2的倍数的一块物理内存区，其他内核对象可通过从其分配
按上述原理发展出的模型具有以下属性：
1. 显式授予所有权限（通过能力）。
2. 数据访问和权限可以受到限制。
3. 内核对于自己的数据结构，包括物理内存的消耗，都遵循分配给应用程序的权限。
4. 每个内核对象都可以独立于任何其他内核对象进行回收。
5. 所有操作都在“短”时间内执行或抢占（对象大小不大于页面的恒定或线性）。  
属性 1-3 确保可以对系统资源和安全性进行推断。特别是属性 3 对于正式地证明内核确保完整性、权限限制和机密性的能力至关重要 [Sewell 等人，2011 年;Murray 等人，2013 年]。属性 5 确保所有内核操作都具有低的有限延迟，因此支持将其用于硬实时系统 [Blackham 等人，2011 年]。内核中有一个长时间运行的操作——即Capability吊销，它需要抢占点（Preempting point）。这些抢占点可确保内核处于一致状态，也确保内核已取得进展，也可检查挂起的中断。如果存在挂起的中断，则内核将返回 usermode 以重新启动系统调用，从而确保中断被首先处理。重新启动的系统调用将继续执行上次尝试已停止的拆解工作。  
属性 4 确保内核完整性。任何合法capability的持有者都可以随时回收对象，这使得原始的 Untyped 对象可再次用于创建对象。例如，页表内存可以在不销毁相应的地址空间的情况下被回收。这要求内核能够检测并取消对正在回收的对象的任何引用。  
Capability派生树有助于满足这一要求。内存对象通过在树的上游的 Untyped 对象上调用 revoke() 方法被撤销；这将删除指向从该 Untyped 派生的所有对象的所有Capability。删除内存对象的最后一个Capability时，对象本身将被删除。这将删除此内核对象可能与其他对象具有的任何内核内依赖关系，从而使其可供重用。删除最后一个Capability的行为很容易检测，因为它会清除Capability树中指向特定内存位置的最后一个叶节点。  
吊销需要用户级别的簿记，以便将Untyped Capabilities与内核对象相关联，通常在用户级别定义的、更高级别抽象（如进程）的粒度上进行关联。Untyped 的精确语义及其与用户级簿记的关系仍在探索中。  
新功能：在 seL4 中对内核内存进行用户级控制，在 Fiasco.OC 中对内核内存配额进行控制。
### 时间
除了内存之外，系统中必须共享的另一个关键资源是 CPU。与内存不同，内存可以细分并在多个进程之间同时有效共享，而 CPU 一次只能由单个线程使用，因此必须进行时间多路复用。  
所有版本的 L4 都通过固定策略调度程序（可在 Fiasco.OC 中插入）实现这种多路复用。尽管违背了策略自由的核心微内核原则，最初的 L4 调度模型——硬优先级轮询仍然存在。过去所有将调度策略移出到用户级别的尝试都失败了，通常是由于无法忍受的开销，或者不完整或特定于某个域。  
特别是专注于实时问题的德累斯顿小组，对时间问题进行了广泛的实验，包括绝对超时（参见第 3.2.4 节）。他们还探索了几种调度方法，以及适用于实时和分析的基于 L4 的实时系统的系统结构 [Hartig 和 Roitzsch ̈ 2006]。  
虽然能够解决一些具体问题，但德累斯顿没有发明出一种无策略的通用机制，Fiasco.OC基本上恢复了传统的L4模式。最近一个关于调度上下文的提案允许将基于优先级的分层调度映射到单个优先级调度程序上 [Lackorzynski 等人，2012 年]，但仅在遗留的 Fiasco 内核（在引入功能之前的内核）中实现，因为它不适配于 IPC Endpoint 提供的间接性。  
有人可能会争辩说，适用于所有目的的单一通用内核的概念可能不像以前那样重要;现在我们已经习惯了环境插件。然而，seL4 的形式化验证对改变内核产生了强大的抑制作用，因为它极大强化了为所有使用场景提供单一平台的愿望，即通用性。因此，以无策略的方式处理时间是一如既往的可取。  
未解决：对 CPU time 进行有原则的无策略控制  
# 微内核实现
Liedtke [1993a] 列举了一组设计决策和实现技巧，这些技巧有助于在原始 i486 版本中加快 IPC，尽管其中一些有过早优化的味道。  
有些已经被提到过，例如现已过时的长IPC中使用的临时映射窗口。其他的则是没有争议的，例如单个系统调用中的发送-接收组合：用于类似 RPC 调用的客户端式 call 和服务端式 reply-and-wait。我们将更详细地讨论其余的内容，包括一些传统的 L4 实现方法，这些方法很少被宣传，但长期以来在社区中被认为是理所当然的。
## 严格的进程导向和虚拟TCB阵列
最初的 L4 中每个线程都有一个单独的内核堆栈，这个堆栈被分配在同一页面上的 TCB 的上方。因此，TCB 的基址相较于堆栈基址处于固定偏移量，可以通过屏蔽内核堆栈指针上的最低有效位来获得。只需要一个 TLB 条目即可囊括线程的 TCB 和堆栈。  
此外，所有 TCB 都分配在一个稀疏的、虚拟寻址的数组中，按线程 ID 编制索引。在 IPC 期间，这样可以非常快速地查找目标 TCB，而无需首先检查 ID 的有效性：如果调用方提供无效 ID，则查找可能会访问未映射的 TCB，从而触发页面错误;内核通过中止 IPC 来处理此问题。如果没有发生任何故障，则可以通过将调用方提供的值与 TCB 中找到的值进行比较来确定线程 ID 的有效性。  
这两种功能都是有代价的：许多内核堆栈占据了每个线程的内存开销，并且它们还增加了内核的缓存占用空间。虚拟 TCB 阵列增加了内核的虚拟内存使用量，从而增加了 TLB 占用空间，但避免了查找表的额外缓存占用空间，否则将需要这些占用空间。具有单个页面大小和未标记 TLB 的处理器除了对数据结构进行分组以最大限度地减少接触的页面数量外，几乎没有优化的机会。但是，RISC 处理器具有较大的页面大小或物理内存寻址，并标记了 TLB，这改变了权衡。此外，与长 IPC 中的页面错误（参见第 3.2.2 节）一样，虚拟 TCB 阵列需要处理嵌套异常，即在内核中触发的页面错误。因此，它增加了显著的内核复杂性和形式化验证的巨大挑战。  
当 L4 在嵌入式领域获得牵引力时，内核的内存使用成为一个重大问题，因此需要重新审视设计。  
在奔腾上使用单堆栈内核的初步实验表明，在微基准测试中，内核内存消耗减少，IPC性能有所提高[Haeberlen 2003]。Warton [2005] 对 Pistachio 进程内核与基于事件的（单堆栈）内核进行了全面的性能评估，并在 ARMv5 处理器上进行了延续。总的来说，他表明二者在微基准测试中表现相当，性能差距在 1% 以内，但在多任务工作负载 （AIM7） 上，事件内核的性能优势为 20%。他还发现，事件内核的每线程内存使用量是进程内核的四分之一，尽管事件内核需要两倍多的 TCB 大小来存储延续。  
同时，Nourai [2005]分析了TCB的虚拟寻址与物理寻址的权衡。他也用开心果实现了物理寻址，尽管是在 MIPS64 处理器上。他发现，在微基准测试中，IPC性能几乎没有差异，但物理寻址内核在给TLB带来压力的工作负载上的性能要好得多。MIPS在某种程度上是异常的，因为即使启用了MMU，它也支持物理寻址，而在大多数其他架构上，“物理”寻址是通过幂等大页面映射来模拟的，可能与“全局”映射结合使用。尽管如此，Nourai的结果令人信服地表明，至少在MIPS处理器上，虚拟寻址的TCB没有性能优势，其他现代处理器不太可能表现出显着不同的权衡。  
避免内核内页面错误异常的基于事件的内核保留了 C 语言的语义。如第 3.2.2 节所述，保持在 C 语义范围内可降低验证的复杂性。  
总之，这些结果促使人们转向基于事件的设计，对 L4 嵌入的内核数据进行物理寻址，seL4 也紧随其后。虽然这一决定最初是由资源匮乏的嵌入式系统的现实以及后来的验证需求驱动的，但这种方法的好处并不局限于这些环境，我们相信它通常是现代硬件上的最佳方法。  
替换：在 seL4、OKL4 和 NOVA 中按事件内核替换进程内核。  
放弃：虚拟 TCB 寻址。  
## 惰性调度
在 IPC 的集合模型中，线程的状态经常在可运行和被阻塞之间交替。这意味着频繁的队列操作，将线程移入和移出就绪队列，通常在一个时间片内多次。  
Liedtke 的惰性调度技巧最大限度地减少了这些队列操作：当线程在 IPC 操作上阻塞时，内核会在 TCB 中更新其状态，但将线程留在就绪队列中，并期望它很快就会解除阻塞。当调度程序在时间片抢占时被调用时，它会遍历就绪队列，直到找到真正可运行的线程并删除不可运行的线程。该方法还辅以唤醒队列的延迟更新。  
延迟调度将工作从高频 IPC 操作转移到不常调用的调度程序。在分析 seL4 的最坏情况执行时间 （WCET） 时，我们观察到了在硬实时系统中使用的缺点 [Blackham et al. 2012]：调度程序的执行时间仅受系统中线程数的限制。  
为了解决这个问题，我们采用了一种替代优化方法，称为 Benno 调度，它不会受到病态计时行为的影响：我们没有将阻塞的线程留在就绪队列中，而是将未阻塞的线程推迟到就绪队列中，直到抢占时间。这会将主调度程序不变性从“所有可运行线程都在就绪队列中”更改为“可运行线程集由当前正在执行的线程加上就绪队列的内容组成”。  
Benno 调度保留了理想的属性，即当线程在 IPC 期间阻塞或取消阻塞时，就绪队列通常不会被修改。在抢占时，内核将（仍可运行但不再执行）抢占线程插入到就绪队列中。这种恒定时间操作是唯一需要的修复。此外，删除超时意味着不再需要操作唤醒队列。端点等待队列必须严格维护，但在服务器响应通过单个端点接收的客户端请求的常见情况下，它们在缓存中是热的，因此这些队列操作的成本很低。这种方法具有与延迟调度相似的平均案例性能，同时还具有有限且较小的 WCET。  
替换：Benno 调度的延迟调度。
## 直接进程切换
传统上，L4 会尽量避免在 IPC 期间运行调度程序。如果线程在 IPC 调用期间被阻塞，则内核将切换到易于识别的可运行线程，然后在原始线程的时间片上执行，通常忽略优先级。这种方法称为直接进程切换。  
这比人们一开始想象的更有意义，尤其是当假设服务器至少与客户端具有相同的优先级时。一方面，如果客户端线程对服务器执行 call 操作，则调用方显然会被阻塞，直到被调用方回复。在能够执行系统调用后，线程必须是优先级最高的可运行线程，观察其优先级的最佳方法是确保被调用方尽快完成，并且无论如何，被调用方可能具有更高的优先级。  
这比人们一开始想象的更有意义，尤其是当假设服务器至少与客户端具有相同的优先级时。一方面，如果客户端线程对服务器执行调用操作，则调用方显然会阻止，直到被调用方回复。在能够执行系统调用后，线程必须是优先级最高的可运行线程，观察其优先级的最佳方法是确保被调用方尽快完成，并且无论如何，被调用方可能具有更高的优先级。  
另一方面，如果服务器使用 reply-and-wait 回复等待客户端，并且服务器有来自另一个客户端的请求等待，则通过执行其 IPC 的接收阶段来继续服务器以利用启动缓存是有意义的。
现代 L4 版本关注正确的实时行为，在符合优先级的地方保留直接进程切换，否则调用调度程序。事实上，直接进程切换是时间片捐赠的一种形式，Steinberg et al. [2005] 表明它可以用来实现优先级继承和优先级上限协议。Fiasco.OC 和 NOVA 通过允许用户在每次通话的基础上指定捐赠来支持这一点。  
替换：直接过程开关取决于 seL4 中的优先级，而在 Fiasco.OC 和 NOVA 中是可选的。
## 抢占
传统上，L4 实现在内核内执行时会禁用中断，尽管有些（如 L4/MIPS）在长时间运行的操作中包含抢占点，其中中断被短暂启用。这种方法大大简化了内核实现，因为大多数内核不需要并发控制，并且通常会导致更好的平均情况性能。  
然而，最初的 L4 ABI 有许多长时间运行的系统调用，早期的 Fiasco 工作使内核处于完全可抢占状态以提高实时性能 [Hohmuth 和 Hartig ̈ 2001]。后来的 ABI 版本删除了大部分长时间运行的操作，Fiasco.OC 恢复了原始的、大部分是非抢占式的实现方法。  
在 seL4 的情况下，非抢占内核还有一个额外的原因：避免并发以使形式验证易于处理 [Klein et al. 2009]。鉴于 seL4 专注于安全关键系统，其中许多系统具有硬实时性，我们需要对中断传输的延迟进行硬性限制。因此，必须避免长时间运行的内核操作，并在不可能使用抢占点，特别是实际上无限制的对象删除。我们在抢占点的放置以及数据结构和算法上投入了大量精力，以最大限度地减少对它们的需求 [Blackham 等人，2012 年]。  
我们注意到，基于延续的事件内核（如 seL4）通过使抢占点成为延续点来为抢占点提供自然支持。  
保留：主要是具有策略抢占点的不可抢占设计。
## 不可移植性
Liedtke [1995] 指出，微内核实现不应该追求可移植性，因为硬件抽象会引入开销并隐藏特定于硬件的优化机会。他引用了“兼容”的 i486 和 Pentium 处理器之间的微妙架构变化，导致了权衡的转变，并暗示了最佳实现的重大变化。  
Liedtke 本人用高性能且便携的 Hazelnut 内核，尤其是 Pistachio 驳斥了这一论点。仔细的设计和实现使得开发 80% 到 90% 与架构无关的实现成为可能。重要的是，这是在没有显式硬件抽象层 （HAL） 的情况下实现的。鉴于 L4 机制的极简主义性质，以及大多数是围绕硬件机制的薄层这一事实，HAL 不会比 seL4 本身小得多。事实上，L4 可以被看作是一个（不完美的）HAL。  
在 seL4 中，与架构无关的代码（介于 x86 和 ARM 之间）仅占 50% 左右。大约一半的代码涉及虚拟内存管理，这必然是特定于体系结构的。可移植代码的较低比例是 seL4 整体规模较小的结果，大多数（与架构无关的）资源管理代码都转移到了用户空间。除了 IPC 快速路径外，几乎没有特定于架构的优化。Steinberg [2013] 近似估计，将 NOVA 移植到 ARM 需要 50% 的重写。  
替换：非可移植的实现，主要由与架构无关的代码取代，没有显式的硬件抽象层。  
## 非标准调用约定
最初的 L4 内核完全是在汇编程序中实现的，因此函数的调用约定在内核中是无关紧要的。在 ABI 中，所有不需要作为系统调用参数的寄存器都被指定为消息寄存器。库接口提供了内联汇编程序存根，用于将编译器的调用约定转换为内核 ABI，希望编译器能够优化任何转换开销。  
下一代 L4 内核，从 L4/MIPS 开始，都至少部分用 C 语言编写。在输入 C 代码时，这些内核必须重新建立 C 编译器的调用约定，并在返回时恢复到内核的约定。这使得调用 C 函数的成本相对较高，因此不鼓励使用 C，除非本质上是昂贵的操作。  
后来的内核几乎完全用C（Hazelnut）或C++（Fiasco，Pistachio）编写。调用约定不匹配的代价，以及缺乏微优化所有代码，意味着 C 代码没有表现出与旧汇编内核相比具有竞争力的性能。因此，这些内核的实现者开始引入手工制作的汇编程序快速路径。这些导致IPC性能与原始L4相当（见表I）。  
传统方法不适合 seL4，因为验证框架只能处理 C 代码 [Klein et al. 2009]，我们希望尽可能完整地验证内核的功能。这需要将汇编程序代码限制在最低限度，并排除调用约定转换，迫使我们采用工具链的标准调用约定  
已放弃：非标准调用约定。  
## 实现语言
seL4 也高度依赖快速路径代码来获得有竞争力的 IPC 性能，但现在必须在 C 语言中实现快速路径。商业 OKL4 内核已经放弃了汇编程序快速路径，因为汇编程序代码的维护成本很高，这在商业环境中超过了任何性能下降。  
对于 seL4，与相同架构上最快的内核相比，我们愿意容忍不超过 10% 的 IPC 性能下降。幸运的是，事实证明，通过精心手工设计快速路径，我们可以实现极具竞争力的IPC延迟[Blackham和Heiser 2012]。具体来说，这意味着手动重新排序语句，利用编译器无法通过静态分析确定的已验证不变量  
事实上，在 ARM11 处理器上，单向 IPC 最终实现的 188 个周期的延迟比我们在相同硬件上的任何其他内核上测得的最快 IPC 高出约 10%。这在一定程度上是由于简化了 seL4 ABI 和 IPC 语义，以及基于事件的内核不再需要在堆栈交换机上保存和恢复 C 调用约定。我们还受益于改进的编译器，特别是它们对常见情况的注释条件分支的支持，这有助于编码局部性。  
无论如何，此结果表明汇编程序实现不再由性能参数证明是合理的。  
Abandoned：用于性能的汇编程序代码。  
第一个完全用高级语言编写的 L4 内核是 Fiasco。开发人员选择了C++而不是C，后者在几年前就被用于MIPS内核的某些部分。考虑到当时 C++ 编译器的状态，这似乎是一个勇敢的决定，但至少部分可以解释为 Fiasco 最初在设计时并没有考虑到性能。同时，C++代码的性能损失显著降低  
卡尔斯鲁厄团队也用C++实现 Pistachio，主要是为了支持可移植性。尽管德累斯顿和卡尔斯鲁厄对 C++ 的热情很高，但我们从未看到 C++ 为微内核实现提供任何令人信服的优势。此外，OK Labs 发现，好的 C++ 编译器的可用性是嵌入式空间中的一个真正问题，他们将微内核版本转换回直接 C。  
对于 seL4，验证要求迫使选择 C。虽然德累斯顿的VFiasco项目试图验证C++内核[Hohmuth和Tews 2005]，但它从未完成对Fiasco使用的C++子集的语义的形式化。相比之下，通过使用 C 语言来实现 seL4，我们可以建立在 C 的现有形式化 [Norrish 1998] 之上，这是验证的关键推动因素。  
放弃：用于 seL4 和 OKL4 的 C++。  
# 其他经验
## 虚拟化
自 Liedtke 的原始工作以来，可能出现的最重要的用例是虚拟化。关于半虚拟化 Linux 的早期工作 [Hartig et al. ̈ 1997] 引领了这一潮流，尽管在这个阶段，虚拟化只是展示全功能系统可实现性能的一种方式。Linux 很快成为德累斯顿小组首选的操作系统中间件，用于支持实时系统中的遗留软件 [Hartig ̈ et al. 1998]。  
在新南威尔士大学/NICTA，对独立于架构的半虚拟化 Linux [Leslie et al. 2005b] 的研究导致高通公司采用并部署在数十亿台移动设备上，包括使用虚拟化在支持应用程序的 Linux 客户机和实时调制解调器软件之间共享单个处理器内核 [Heiser 2009]。
虚拟化的硬件支持消除了大部分工程难题，并可以轻松为虚拟机提供接近原生的性能。与大多数主流虚拟机管理程序相反，用作虚拟机管理程序的 L4 内核最大限度地减少了可信计算基础，至少在虚拟机之间的隔离方面是这样。具体来说，当充当虚拟机管理程序时，微内核保留了其作为上下文切换引擎的角色，只不过是将虚拟化异常转发到用户模式虚拟机监视器 （VMM），就像它将中断转发到设备驱动程序一样  
图 2 显示了此体系结构，其中显示了各种组件及其权限级别。VMM 已取消特权，每个虚拟机都有一个 VMM 实例 [Steinberg 和 Kauer 2010]。因此，虽然 VMM 是虚拟机受信任计算基础的一部分，但它不受系统的任何其他部分的信任;特别是，它无法打破虚拟机之间的隔离。  
seL4 VMM 约为 20,000 SLOC。当与 seL4 本身的 9,000 个 SLOC 结合使用时，这些结果与 Steinberg 和 Kauer [2010] 报告的针对特权 VMM 及其虚拟化特定内核变体 （NOVA） 的结果相似。正如他们所观察到的，共享的可信计算基础的规模比竞争的单体虚拟机管理程序小几个数量级。  
虚拟化导致了一些专门设计为虚拟机管理程序的内核变体，并且要么在通用性 （OKL4） 上妥协，要么在最小性 （NOVA） 上妥协。但是，seL4 几乎没有特定于虚拟化的功能，主要是上下文切换额外的虚拟机状态并提供与虚拟机相关的异常。支持虚拟化的需求需要重新思考一些设计决策，这通常会导致更简洁、更通用的机制。  
虚拟化是更简洁、更通用模型的驱动力  
## 多核
多处理器问题在 L4 社区的早期就被探索过了。尽管 L4/Alpha 和 L4/MIPS 的大部分工作都是在 x86 平台上完成的，这些平台是最早的经济实惠的多处理器。早期的 x86 多处理器和多核具有较高的内核间通信成本，并且没有共享缓存。因此，标准方法是使用每个处理器的调度队列，并且通常最大限度地减少内核之间内核数据的共享;线程仅在用户空间的显式请求下迁移。Uhlig [2005] 探索了具有许多内核的平台上的锁定、同步和一致性问题，并开发了基于 RCU 的内核数据结构的可扩展并发控制方法 [McKenney et al. 2002]。NOVA 和 Fiasco.OC 广泛使用 RCU。  
随着重点从高端服务器转向嵌入式和实时平台，多处理器问题退居幕后，直到最近随着嵌入式处理器多核版本的出现才重新出现。它们的特点是核心间通信成本低，并且通常共享 L2 缓存，这意味着权衡与 x86 上的权衡不同，因为局部性不是问题。  
验证还引入了新的约束。正如第 3.2.2 节所讨论的，并发性给验证带来了巨大的挑战，我们尽可能地将其排除在 seL4 内核之外。对于多核，这意味着采用大内核锁或多内核方法 [Baumann et al. 2009]。对于系统调用时间较短的微内核，前者并不像一开始看起来那么愚蠢，因为锁争用会很低，至少对于共享最后一级缓存的少数内核来说是这样 [Peters et al. 2015]。此外，在没有共享片上缓存的松散耦合众核上，共享任何内核数据都毫无意义。在这样的架构上，迁移几行缓存行的延迟在数千或数万个周期内 [Baumann 等人，2009 年]，因此比典型的 L4 系统调用大几个数量级。  
我们目前正在探索一个集群化的多内核（图3）：一个大锁内核的混合体，跨共享缓存的内核，以及一个受限的多内核变体，其中不允许内核之间的内存迁移[von Tessin 2012]。集群多内核避免了大多数内核代码的并发性，这使得一些形式保证在某些假设下能够继续保持。最重要的假设是 （1） 锁本身以及锁之外的任何代码都是正确的并且 （2） 内核对内核和用户级之间共享的内存的任何并发更改都是鲁棒的。对于 seL4，唯一满足上述条件的内存是虚拟 IPC 消息寄存器块。  
请注意，虽然聚类方法在内核映像之间静态划分内存，这自然映射到 NUMA 平台，但这并不妨碍用户空间将所有内存视为共享。事实上，每个内核实例都以虚拟 CPU 的形式呈现给未经修改的 SMP Linux 客户机，该客户机能够有效地支持高吞吐量工作负载 [Heiser 等人，2013 年]。  
这种方法的吸引力在于，它保留了现有的单处理器证明并仅有少数修改。von Tessin [2013] 提升了单处理器自动机的并行组合，并表明改进仍然成立。但是，形式化的保证不再涵盖整个系统，而只涵盖单个内核集群。提升框架使用的大步骤语义假定内核代码在抢占机会之间是原子的。这不允许扩展正式框架以涵盖有关锁的正确性、用户内核并发性以及任何资源迁移限制的放宽的推理。这种推理需要小步语义，即在指令级别进行建模。  
集群多内核的变体最终可能是获得多处理器内核完整形式验证的最佳方法，尽管我们在这里没有提出强有力的主张。在形式方面需要做更多的工作来推理微内核规模的细粒度交错。  
未解决：验证时代对多核处理器的处理。
## 体系结构的影响
表I显示了（微）架构对上下文切换的巨大影响，从而对IPC成本产生了巨大影响。就周期而言，这些周期在 x86 上不断增加，最终在世纪之交的 Pentium 4 （NetBurst） 架构上实现了 2,000 个周期的 IPC。这给微内核带来了真正的挑战：我们的经验是，花费几百个周期的上下文切换很少重要，而数千个周期就会成为系统性能问题，例如，对于高带宽网络接口的用户级驱动程序。  
幸运的是，随着对功耗的日益关注，架构趋势发生了逆转：最新一代的 x86 处理器，从 Haswell 微架构开始，实现了与 RISC 处理器相当的上下文切换时间。有趣的是，ARM 处理器的趋势是朝着更昂贵的上下文切换方向发展。然而，随着标记的 TLB 现在成为标准，激进的猜测显然已经死了，而且由于需要序列化许多隐藏状态，越来越多的架构寄存器不再强制长时间的陷入延迟，希望事情永远不会再像 NetBurst 那样糟糕。  
一个真正重要的架构进步是引入了 I/O MMU，作为虚拟化硬件辅助的一部分。这支持低开销的用户级驱动程序，即使对于使用 DMA 的设备也是如此。在此之前，此类设备的用户级驱动程序必须是可信的，这否定了从内核中删除它们的大部分好处，或者 DMA 必须通过昂贵的（在工程工作量和运行时成本方面）驱动程序的半虚拟化来控制。在这里，微内核受益于这样一个事实，即它们面临着与虚拟机管理程序相同的问题，即需要取消设备驱动程序的特权。  
架构很重要。
## 形式化验证的影响
我们自始至终都在评论验证对 seL4 设计和实现的影响。具体而言，验证禁止或不鼓励进行
— 弱且无原则的资源管理模型（第 3.4.3 节）
— 可配置的变体，例如可插拔调度程序（第 3.4.4 节）
— 嵌套异常（第 4.1 节）
— 非标准调用约定（第 4.6 节）
— 汇编代码（第 4.7 节）
— 并发和锁定（第 5.2 节）。  
虽然处理这些限制有时需要更多努力，但事后看来，这些挑战始终导致更有原则、更简洁的设计。由此产生的解决方案不可避免地更接近于极简和更普遍。换言之，验证有力地强化了极简性和通用性的核心原则，这些原则真正构成了 L4 哲学的核心。  
最重要的是，验证对实现者施加了一些编程规则。这些几乎都符合良好的软件工程实践，因此并不是真正的限制。主要的例外是禁止将对自动变量的引用传递给函数 [Klein et al. 2009]。这不是验证的固有要求，而是验证和实现之间的权衡。这是我们迄今为止观察到的验证的唯一缺点，可以通过对验证结构进行更多投资来消除。  
我们对验证最大的担忧是，它可能会迫使我们牺牲性能或阻止我们发展内核，但事实证明这两者都是没有根据的：seL4 是性能最好的 L4 内核，可以直接比较（参见第 4.7 节），我们发现保持更新内核的证明的成本与升级内核实现的成本成比例 [Klein et al. 2014]。  
验证强制要求进行干净和有原则的设计和实施，鼓励最小化和通用性，并且没有明显的缺点。  
# 结论
很少有研究型操作系统既有重要的开发人员社区，又有重要的商业部署，以及长期的演进。L4 就是这样一个系统，它经历了 20 年的 API 发展、设计和实现原则，以及大约十几个从头开始的实现。我们认为这是一个很好的机会，可以反思基本原则，并检查哪些设计和实现方法经受住了时间的考验，哪些方法未能在不断深入的理解、不断变化的部署场景和 CPU 架构的演变中幸存下来。  
如表IV所示，设计选择和实现技巧来来去去，包括一些接近原始设计者内心的技巧。然而，L4 背后的最一般原则，即最小性，包括在用户级别运行设备驱动程序、通用性和对性能的强烈关注，在开发人员的脑海中仍然具有相关性和首要意义。具体来说，我们发现关键的微内核性能指标，即IPC延迟，在时钟周期方面基本保持不变，只要在截然不同的ISA和微架构之间的比较具有任何有效性。这与 Ousterhout [1990] 在 L4 创建前几年确定的趋势形成鲜明对比。此外，也许最令人惊讶的是，代码大小基本上保持不变，这在软件系统中是一个相当不寻常的发展  
形式化验证增加了最低限度和通用性的重要性，也增加了简化执行的压力。一些设计决策，如简化的消息结构、内核内存的用户级控制以及多核方法，都受到验证的强烈影响。它还影响了许多实现方法，例如使用面向事件的内核、采用标准调用约定以及选择 C 作为实现语言。但是，这不会导致我们认为忽略验证的权衡更差;当然，这并没有导致损害通用性、性能和极简性的最初目标。  
通过形式化验证，L4 令人信服地兑现了微内核多年前做出的核心承诺之一：健壮性。我们认为这很好地证明了 Liedtke 原始 L4 设计的辉煌，这是在忠于原始 L4 理念的同时实现的，或者可能是由于忠于原始 L4 理念。这可能花了很长时间，但时间终于证明了布林奇·汉森（Brinch Hansen，1970）曾经激进的想法是正确的。  
还有一些问题有待解决。例如，在形式验证的背景下，多核的正确方法是一个悬而未决的问题，尽管最近取得了进展。  
到目前为止，有一个概念抵制了任何令人满意的抽象：时间。L4 内核仍然实现特定的调度策略（在大多数情况下是基于优先级的循环），这是内核中最后一个主要的策略保留。这可能代表了当代 L4 内核通用性的最大限制。正在进行的工作表明，单个参数化的内核调度器实际上可能能够支持所有标准调度策略 [Lyons and Heiser 2014]，我们预计它在不到20年的时间就可以实现。